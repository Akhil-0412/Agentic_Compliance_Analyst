# Agentic GDPR Compliance Analyst âš–ï¸

> A deterministic legal reasoning engine that combines **Vector Retrieval (RAG)** with **Logic State Machines** and **Human-in-the-Loop Governance**.

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![Groq](https://img.shields.io/badge/LLM-Llama3%2070B-orange)
![Streamlit](https://img.shields.io/badge/UI-Streamlit-red)

## ğŸ§  The Problem
Most "Legal AI" chatbots fail because they treat law as a retrieval task. They search for keywords but miss the **logic hierarchy**.
* *Example:* A "Processor" who violates instructions becomes a "Controller" (Art 28.10). Standard RAG misses this state change and quotes the wrong fine tier.

## ğŸ’¡ The Solution: Cognitive Architecture
This system is not a chatbot. It is a **Reasoning Engine** with three distinct layers:

1.  **Domain Logic Router:** Injects necessary context based on legal intent (e.g., forcing Article 28 context when Article 83 is queried).
2.  **Legal State Machine:** Evaluates role mutability (Controller vs. Processor) before calculating penalties.
3.  **Governance Vault:** A deterministic "Supreme Court" layer that prevents hallucination and enforces human oversight for critical risks.

## ğŸ—ï¸ Architecture
```mermaid
graph TD
    User[ğŸ‘¤ User Query] --> Guard[ğŸ›¡ï¸ Intent Guardrail]
    Guard -- "Safe" --> Router{ğŸ§  Domain Logic Router}

    subgraph "Reasoning State Machine"
        Router --> StateA[Inject Art 83 + Guidelines]
        Router --> StateB[Inject Art 28 + Art 4]
        StateA & StateB --> Search[ğŸ” Vector Retrieval]
    end

    Search --> LLM[ğŸ¤– Llama 3 70B (w/ Mixtral Failover)]
    
    subgraph "Governance Layer"
        LLM --> Check{âš–ï¸ Risk Gate}
        Check -- "Critical Risk" --> Human[âš ï¸ Human Review]
        Check -- "High Confidence" --> Auto[âœ… Auto-Approve]
    end

    Human --> UI[ğŸ–¥ï¸ Streamlit Dashboard]
    UI -- "Expert Edit" --> Validator[ğŸ‘¨â€âš–ï¸ Supreme Court Agent]